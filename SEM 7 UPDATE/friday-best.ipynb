{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d8c38c-bdff-4402-93f5-9032a12f8f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda img_size: 128\n",
      "Loaded images: 50000\n",
      "Models initialized\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5156/956504163.py:341: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_G = GradScaler()\n",
      "/tmp/ipykernel_5156/956504163.py:342: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_D = GradScaler()\n",
      "/tmp/ipykernel_5156/956504163.py:343: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler_Dec = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/user7/.local/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5156/956504163.py:381: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_5156/956504163.py:393: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_5156/956504163.py:414: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0800, G_loss=20.2044, Dec_loss=3.2343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Avg Val PSNR = 20.014 dB | SSIM = 0.6705 | NRPC = 0.9967 | USEI(UQI) = 0.8954 | LPIPS = 0.0473 | RecAcc = 0.5974 | bpp = 10.6102\n",
      "Saved best models (PSNR 20.01 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0594, G_loss=12.5293, Dec_loss=2.0196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Avg Val PSNR = 21.015 dB | SSIM = 0.6813 | NRPC = 0.9978 | USEI(UQI) = 0.9372 | LPIPS = 0.0171 | RecAcc = 0.5962 | bpp = 9.8595\n",
      "Saved best models (PSNR 21.02 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0183, G_loss=7.1529, Dec_loss=1.1120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Avg Val PSNR = 25.762 dB | SSIM = 0.8347 | NRPC = 0.9980 | USEI(UQI) = 0.9765 | LPIPS = 0.0084 | RecAcc = 0.6507 | bpp = 9.7024\n",
      "Saved best models (PSNR 25.76 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0214, G_loss=4.8663, Dec_loss=0.6713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Avg Val PSNR = 27.572 dB | SSIM = 0.8690 | NRPC = 0.9985 | USEI(UQI) = 0.9824 | LPIPS = 0.0054 | RecAcc = 0.6600 | bpp = 9.2187\n",
      "Saved best models (PSNR 27.57 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0142, G_loss=5.2876, Dec_loss=0.6897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Avg Val PSNR = 26.312 dB | SSIM = 0.8612 | NRPC = 0.9988 | USEI(UQI) = 0.9812 | LPIPS = 0.0040 | RecAcc = 0.6529 | bpp = 8.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0077, G_loss=4.2299, Dec_loss=0.6005]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Avg Val PSNR = 26.469 dB | SSIM = 0.8570 | NRPC = 0.9991 | USEI(UQI) = 0.9847 | LPIPS = 0.0030 | RecAcc = 0.6501 | bpp = 8.3252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0175, G_loss=3.5320, Dec_loss=0.5018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Avg Val PSNR = 28.186 dB | SSIM = 0.8734 | NRPC = 0.9992 | USEI(UQI) = 0.9876 | LPIPS = 0.0028 | RecAcc = 0.6562 | bpp = 8.1805\n",
      "Saved best models (PSNR 28.19 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0248, G_loss=4.0483, Dec_loss=0.5422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Avg Val PSNR = 29.338 dB | SSIM = 0.9097 | NRPC = 0.9994 | USEI(UQI) = 0.9879 | LPIPS = 0.0022 | RecAcc = 0.6638 | bpp = 7.6404\n",
      "Saved best models (PSNR 29.34 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.74it/s, D_loss=0.0604, G_loss=2.6578, Dec_loss=0.3565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Avg Val PSNR = 30.275 dB | SSIM = 0.8997 | NRPC = 0.9994 | USEI(UQI) = 0.9915 | LPIPS = 0.0022 | RecAcc = 0.6790 | bpp = 7.6609\n",
      "Saved best models (PSNR 30.27 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.74it/s, D_loss=0.0148, G_loss=2.4977, Dec_loss=0.3062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Avg Val PSNR = 30.425 dB | SSIM = 0.9048 | NRPC = 0.9995 | USEI(UQI) = 0.9915 | LPIPS = 0.0019 | RecAcc = 0.6843 | bpp = 7.4537\n",
      "Saved best models (PSNR 30.43 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0176, G_loss=3.9327, Dec_loss=0.5483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Avg Val PSNR = 29.574 dB | SSIM = 0.9073 | NRPC = 0.9995 | USEI(UQI) = 0.9897 | LPIPS = 0.0022 | RecAcc = 0.6771 | bpp = 7.3075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.74it/s, D_loss=0.0226, G_loss=3.4129, Dec_loss=0.4362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Avg Val PSNR = 28.513 dB | SSIM = 0.8953 | NRPC = 0.9996 | USEI(UQI) = 0.9892 | LPIPS = 0.0016 | RecAcc = 0.6675 | bpp = 6.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.75it/s, D_loss=0.0304, G_loss=2.8647, Dec_loss=0.3530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Avg Val PSNR = 29.883 dB | SSIM = 0.8979 | NRPC = 0.9997 | USEI(UQI) = 0.9916 | LPIPS = 0.0015 | RecAcc = 0.6810 | bpp = 6.7420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0271, G_loss=2.6150, Dec_loss=0.3675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Avg Val PSNR = 27.781 dB | SSIM = 0.8748 | NRPC = 0.9997 | USEI(UQI) = 0.9879 | LPIPS = 0.0013 | RecAcc = 0.6432 | bpp = 6.5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.73it/s, D_loss=0.0412, G_loss=3.2388, Dec_loss=0.4117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Avg Val PSNR = 30.883 dB | SSIM = 0.9197 | NRPC = 0.9997 | USEI(UQI) = 0.9926 | LPIPS = 0.0012 | RecAcc = 0.6824 | bpp = 6.3689\n",
      "Saved best models (PSNR 30.88 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0251, G_loss=2.4471, Dec_loss=0.3189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Avg Val PSNR = 31.254 dB | SSIM = 0.9284 | NRPC = 0.9998 | USEI(UQI) = 0.9933 | LPIPS = 0.0012 | RecAcc = 0.6904 | bpp = 6.3466\n",
      "Saved best models (PSNR 31.25 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:51<00:00,  5.73it/s, D_loss=0.0151, G_loss=2.3545, Dec_loss=0.2823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Avg Val PSNR = 28.740 dB | SSIM = 0.8994 | NRPC = 0.9998 | USEI(UQI) = 0.9910 | LPIPS = 0.0012 | RecAcc = 0.6702 | bpp = 6.3728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:51<00:00,  5.73it/s, D_loss=0.0332, G_loss=3.2582, Dec_loss=0.4457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Avg Val PSNR = 28.170 dB | SSIM = 0.8695 | NRPC = 0.9998 | USEI(UQI) = 0.9896 | LPIPS = 0.0011 | RecAcc = 0.6602 | bpp = 6.2520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.73it/s, D_loss=0.0268, G_loss=2.2725, Dec_loss=0.2757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Avg Val PSNR = 32.326 dB | SSIM = 0.9358 | NRPC = 0.9998 | USEI(UQI) = 0.9942 | LPIPS = 0.0012 | RecAcc = 0.7017 | bpp = 6.3793\n",
      "Saved best models (PSNR 32.33 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0209, G_loss=2.5116, Dec_loss=0.3313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Avg Val PSNR = 32.225 dB | SSIM = 0.9355 | NRPC = 0.9998 | USEI(UQI) = 0.9940 | LPIPS = 0.0011 | RecAcc = 0.7022 | bpp = 6.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0170, G_loss=3.0645, Dec_loss=0.4324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Avg Val PSNR = 28.094 dB | SSIM = 0.8543 | NRPC = 0.9998 | USEI(UQI) = 0.9894 | LPIPS = 0.0009 | RecAcc = 0.6408 | bpp = 5.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.73it/s, D_loss=0.0133, G_loss=2.3553, Dec_loss=0.2824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Avg Val PSNR = 31.516 dB | SSIM = 0.9326 | NRPC = 0.9998 | USEI(UQI) = 0.9938 | LPIPS = 0.0010 | RecAcc = 0.6957 | bpp = 6.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0180, G_loss=2.1360, Dec_loss=0.2516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Avg Val PSNR = 30.201 dB | SSIM = 0.9000 | NRPC = 0.9998 | USEI(UQI) = 0.9925 | LPIPS = 0.0010 | RecAcc = 0.6806 | bpp = 5.9982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.79it/s, D_loss=0.0140, G_loss=2.1337, Dec_loss=0.2450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Avg Val PSNR = 30.749 dB | SSIM = 0.9171 | NRPC = 0.9998 | USEI(UQI) = 0.9937 | LPIPS = 0.0009 | RecAcc = 0.6871 | bpp = 5.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0143, G_loss=1.8427, Dec_loss=0.2158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Avg Val PSNR = 30.931 dB | SSIM = 0.9142 | NRPC = 0.9998 | USEI(UQI) = 0.9934 | LPIPS = 0.0009 | RecAcc = 0.6890 | bpp = 5.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.78it/s, D_loss=0.0161, G_loss=2.2794, Dec_loss=0.2873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Avg Val PSNR = 32.791 dB | SSIM = 0.9388 | NRPC = 0.9998 | USEI(UQI) = 0.9951 | LPIPS = 0.0008 | RecAcc = 0.7028 | bpp = 5.8141\n",
      "Saved best models (PSNR 32.79 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.78it/s, D_loss=0.0170, G_loss=1.9874, Dec_loss=0.2137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Avg Val PSNR = 33.492 dB | SSIM = 0.9507 | NRPC = 0.9998 | USEI(UQI) = 0.9956 | LPIPS = 0.0008 | RecAcc = 0.7114 | bpp = 5.7824\n",
      "Saved best models (PSNR 33.49 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0059, G_loss=2.0837, Dec_loss=0.2544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Avg Val PSNR = 33.776 dB | SSIM = 0.9480 | NRPC = 0.9998 | USEI(UQI) = 0.9958 | LPIPS = 0.0008 | RecAcc = 0.7186 | bpp = 5.7192\n",
      "Saved best models (PSNR 33.78 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0227, G_loss=2.4988, Dec_loss=0.3024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Avg Val PSNR = 33.651 dB | SSIM = 0.9554 | NRPC = 0.9998 | USEI(UQI) = 0.9956 | LPIPS = 0.0008 | RecAcc = 0.7145 | bpp = 5.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0094, G_loss=1.7996, Dec_loss=0.2085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Avg Val PSNR = 34.243 dB | SSIM = 0.9562 | NRPC = 0.9999 | USEI(UQI) = 0.9959 | LPIPS = 0.0008 | RecAcc = 0.7210 | bpp = 5.7499\n",
      "Saved best models (PSNR 34.24 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.77it/s, D_loss=0.0093, G_loss=2.0544, Dec_loss=0.2423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Avg Val PSNR = 34.611 dB | SSIM = 0.9589 | NRPC = 0.9998 | USEI(UQI) = 0.9963 | LPIPS = 0.0008 | RecAcc = 0.7260 | bpp = 5.7508\n",
      "Saved best models (PSNR 34.61 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:47<00:00,  5.79it/s, D_loss=0.0120, G_loss=2.3455, Dec_loss=0.2827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Avg Val PSNR = 34.358 dB | SSIM = 0.9527 | NRPC = 0.9998 | USEI(UQI) = 0.9963 | LPIPS = 0.0008 | RecAcc = 0.7230 | bpp = 5.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0103, G_loss=2.1320, Dec_loss=0.2492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Avg Val PSNR = 30.770 dB | SSIM = 0.9117 | NRPC = 0.9999 | USEI(UQI) = 0.9937 | LPIPS = 0.0008 | RecAcc = 0.6776 | bpp = 5.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0064, G_loss=1.8470, Dec_loss=0.2190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Avg Val PSNR = 34.850 dB | SSIM = 0.9613 | NRPC = 0.9999 | USEI(UQI) = 0.9965 | LPIPS = 0.0007 | RecAcc = 0.7286 | bpp = 5.6867\n",
      "Saved best models (PSNR 34.85 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0165, G_loss=1.9447, Dec_loss=0.2396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Avg Val PSNR = 31.237 dB | SSIM = 0.9266 | NRPC = 0.9999 | USEI(UQI) = 0.9940 | LPIPS = 0.0007 | RecAcc = 0.6853 | bpp = 5.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.78it/s, D_loss=0.0084, G_loss=2.0742, Dec_loss=0.2474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Avg Val PSNR = 33.802 dB | SSIM = 0.9469 | NRPC = 0.9999 | USEI(UQI) = 0.9963 | LPIPS = 0.0007 | RecAcc = 0.7158 | bpp = 5.6481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0089, G_loss=1.9894, Dec_loss=0.2414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Avg Val PSNR = 33.933 dB | SSIM = 0.9521 | NRPC = 0.9999 | USEI(UQI) = 0.9957 | LPIPS = 0.0008 | RecAcc = 0.7179 | bpp = 5.7943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0153, G_loss=2.2089, Dec_loss=0.2360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Avg Val PSNR = 32.743 dB | SSIM = 0.9323 | NRPC = 0.9999 | USEI(UQI) = 0.9954 | LPIPS = 0.0007 | RecAcc = 0.7133 | bpp = 5.7020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0148, G_loss=2.4763, Dec_loss=0.3051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Avg Val PSNR = 32.116 dB | SSIM = 0.9462 | NRPC = 0.9999 | USEI(UQI) = 0.9936 | LPIPS = 0.0007 | RecAcc = 0.6887 | bpp = 5.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:47<00:00,  5.79it/s, D_loss=0.0038, G_loss=1.8854, Dec_loss=0.2118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Avg Val PSNR = 34.534 dB | SSIM = 0.9579 | NRPC = 0.9999 | USEI(UQI) = 0.9965 | LPIPS = 0.0007 | RecAcc = 0.7285 | bpp = 5.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:48<00:00,  5.77it/s, D_loss=0.0047, G_loss=1.8785, Dec_loss=0.2110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Avg Val PSNR = 34.985 dB | SSIM = 0.9623 | NRPC = 0.9999 | USEI(UQI) = 0.9966 | LPIPS = 0.0007 | RecAcc = 0.7329 | bpp = 5.6182\n",
      "Saved best models (PSNR 34.98 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0102, G_loss=1.7441, Dec_loss=0.2067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Avg Val PSNR = 34.470 dB | SSIM = 0.9523 | NRPC = 0.9999 | USEI(UQI) = 0.9965 | LPIPS = 0.0007 | RecAcc = 0.7287 | bpp = 5.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0071, G_loss=1.9017, Dec_loss=0.2399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Avg Val PSNR = 32.404 dB | SSIM = 0.9378 | NRPC = 0.9999 | USEI(UQI) = 0.9951 | LPIPS = 0.0007 | RecAcc = 0.6901 | bpp = 5.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:45<00:00,  5.85it/s, D_loss=0.0105, G_loss=1.8067, Dec_loss=0.1970]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Avg Val PSNR = 34.662 dB | SSIM = 0.9542 | NRPC = 0.9999 | USEI(UQI) = 0.9966 | LPIPS = 0.0007 | RecAcc = 0.7305 | bpp = 5.6245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0034, G_loss=1.7883, Dec_loss=0.2024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Avg Val PSNR = 35.105 dB | SSIM = 0.9641 | NRPC = 0.9999 | USEI(UQI) = 0.9968 | LPIPS = 0.0007 | RecAcc = 0.7344 | bpp = 5.5568\n",
      "Saved best models (PSNR 35.10 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.76it/s, D_loss=0.0054, G_loss=2.0299, Dec_loss=0.2426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Avg Val PSNR = 34.976 dB | SSIM = 0.9600 | NRPC = 0.9999 | USEI(UQI) = 0.9968 | LPIPS = 0.0007 | RecAcc = 0.7287 | bpp = 5.5496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.74it/s, D_loss=0.0044, G_loss=1.7168, Dec_loss=0.1827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Avg Val PSNR = 35.823 dB | SSIM = 0.9688 | NRPC = 0.9999 | USEI(UQI) = 0.9972 | LPIPS = 0.0007 | RecAcc = 0.7416 | bpp = 5.6065\n",
      "Saved best models (PSNR 35.82 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.74it/s, D_loss=0.0061, G_loss=2.1538, Dec_loss=0.2673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Avg Val PSNR = 34.106 dB | SSIM = 0.9515 | NRPC = 0.9999 | USEI(UQI) = 0.9961 | LPIPS = 0.0007 | RecAcc = 0.7245 | bpp = 5.6055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:49<00:00,  5.75it/s, D_loss=0.0047, G_loss=1.6088, Dec_loss=0.1662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Avg Val PSNR = 34.874 dB | SSIM = 0.9629 | NRPC = 0.9999 | USEI(UQI) = 0.9970 | LPIPS = 0.0007 | RecAcc = 0.7255 | bpp = 5.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|█████████████████████████████████████████████████████████| 1667/1667 [04:50<00:00,  5.75it/s, D_loss=0.0062, G_loss=1.7635, Dec_loss=0.1813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Avg Val PSNR = 34.877 dB | SSIM = 0.9577 | NRPC = 0.9999 | USEI(UQI) = 0.9969 | LPIPS = 0.0007 | RecAcc = 0.7289 | bpp = 5.6439\n",
      "Training finished. Best PSNR: 35.82306431723115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5156/956504163.py:534: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(os.path.join(log_dir,\"G_best.pth\"), map_location=device))\n",
      "/tmp/ipykernel_5156/956504163.py:535: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  Dec.load_state_dict(torch.load(os.path.join(log_dir,\"Dec_best.pth\"), map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualization to runs_steg_20251114_114126/stegano_results_best.png\n",
      "All plots, CSVs and sample images saved to runs_steg_20251114_114126\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Stegano Training + Comprehensive Evaluation (reduced metrics)\n",
    "- Keeps: PSNR, SSIM, NRPC, USEI (UQI), LPIPS (optional)\n",
    "- Adds: Recovery bitstream accuracy, Residual-signal estimated capacity (bpp)\n",
    "- Adds separate graphs for every metric.\n",
    "- Usage: same as your original script — ensure dataset path correct.\n",
    "\"\"\"\n",
    "\n",
    "import os, math, torch, torch.nn as nn, torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from pytorch_msssim import ssim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim_sk\n",
    "\n",
    "# Optional / best-effort imports\n",
    "has_lpips = False\n",
    "try:\n",
    "    import lpips\n",
    "    has_lpips = True\n",
    "except Exception:\n",
    "    print(\"lpips not available — LPIPS will be skipped. Install with 'pip install lpips'\")\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(42)\n",
    "\n",
    "img_size = 128\n",
    "batch_size = 24\n",
    "lr = 1e-4\n",
    "epochs = 50\n",
    "lambda_ssim = 1.0\n",
    "lambda_rec = 15.0\n",
    "lambda_perc = 0.5\n",
    "save_every = 5\n",
    "DATA_FOLDER = \"img_128x_50000\"\n",
    "\n",
    "print(\"Device:\", device, \"img_size:\", img_size)\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        patterns = [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]\n",
    "        self.paths = []\n",
    "        for p in patterns:\n",
    "            self.paths += sorted(glob(os.path.join(folder_path, \"*\" + p)))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        if self.transform: img = self.transform(img)\n",
    "        return img, 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(0.1,0.1,0.1,0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(DATA_FOLDER, transform=transform)\n",
    "print(\"Loaded images:\", len(dataset))\n",
    "\n",
    "# -----------------------------\n",
    "# Utility metrics\n",
    "# -----------------------------\n",
    "def psnr_t(a, b, data_range=2.0):\n",
    "    mse_val = F.mse_loss(a, b).item()\n",
    "    if mse_val == 0: return float(\"inf\")\n",
    "    return 10 * math.log10((data_range ** 2) / mse_val)\n",
    "\n",
    "def tensor_to_vgg_input(x):\n",
    "    x = (x + 1) / 2\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).to(x.device).view(1,3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).to(x.device).view(1,3,1,1)\n",
    "    return (x - mean) / std\n",
    "\n",
    "def compute_nrpc(cover, stego):\n",
    "    c = ((cover + 1) / 2).detach().cpu().numpy()\n",
    "    s = ((stego + 1) / 2).detach().cpu().numpy()\n",
    "    res_c = c - np.mean(c)\n",
    "    res_s = s - np.mean(s)\n",
    "    num = np.sum(res_c * res_s)\n",
    "    denom = np.sqrt(np.sum(res_c ** 2) * np.sum(res_s ** 2)) + 1e-12\n",
    "    return float(num / denom)\n",
    "\n",
    "def compute_usei_uqi(a, b):\n",
    "    a_np = ((a + 1) / 2).detach().cpu().numpy()\n",
    "    b_np = ((b + 1) / 2).detach().cpu().numpy()\n",
    "    Bs = a_np.shape[0]\n",
    "    vals = []\n",
    "    for i in range(Bs):\n",
    "        uqi_ch = []\n",
    "        for ch in range(a_np.shape[1]):\n",
    "            x = a_np[i,ch].flatten()\n",
    "            y = b_np[i,ch].flatten()\n",
    "            mean_x = x.mean(); mean_y = y.mean()\n",
    "            cov = np.mean((x-mean_x)*(y-mean_y))\n",
    "            var_x = x.var(); var_y = y.var()\n",
    "            num = 4 * mean_x * mean_y * cov\n",
    "            den = (mean_x**2 + mean_y**2) * (var_x + var_y) + 1e-12\n",
    "            uqi = num/den\n",
    "            uqi_ch.append(uqi)\n",
    "        vals.append(np.mean(uqi_ch))\n",
    "    return float(np.mean(vals))\n",
    "\n",
    "def image_to_uint8(t):\n",
    "    # t expected in [-1,1]; convert -> [0,255] uint8\n",
    "    with torch.no_grad():\n",
    "        x = ((t + 1) / 2.0 * 255.0).round().clamp(0,255).to(torch.uint8).cpu().numpy()\n",
    "    return x  # shape: (B, C, H, W), dtype=uint8\n",
    "\n",
    "def batch_bitstream_accuracy(secret_t, recovered_t):\n",
    "    \"\"\"\n",
    "    Convert secret and recovered images to 8-bit/channel bitstreams and compute bit accuracy.\n",
    "    Returns (matches / total_bits) as float.\n",
    "    \"\"\"\n",
    "    s_uint8 = image_to_uint8(secret_t)\n",
    "    r_uint8 = image_to_uint8(recovered_t)\n",
    "    # pack bits per byte (big-endian) -> shape (..., 8)\n",
    "    # flatten across batch, channels, height, width\n",
    "    s_flat = s_uint8.reshape(-1).astype(np.uint8)\n",
    "    r_flat = r_uint8.reshape(-1).astype(np.uint8)\n",
    "    # convert to bits\n",
    "    s_bits = np.unpackbits(s_flat)\n",
    "    r_bits = np.unpackbits(r_flat)\n",
    "    # safety: lengths same\n",
    "    total_bits = s_bits.size\n",
    "    if total_bits == 0:\n",
    "        return float('nan')\n",
    "    matches = int(np.sum(s_bits == r_bits))\n",
    "    return matches / total_bits\n",
    "\n",
    "def residual_bpp_estimate(cover, stego):\n",
    "    \"\"\"\n",
    "    Estimate residual bit-capacity (bpp) from residual distribution.\n",
    "    - residual = stego - cover  (both in [-1,1])\n",
    "    - map residual to 0..255 and compute Shannon entropy (bits per channel symbol)\n",
    "    - multiply by number of channels (3) => bits per pixel (bpp)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        resid = (stego - cover).detach().cpu().numpy()  # shape (B,C,H,W)\n",
    "    # map resid from [-2,2] into [0,255] (since st ranges [-1,1], resid in [-2,2])\n",
    "    mapped = ((resid + 2.0) / 4.0 * 255.0).round().clip(0,255).astype(np.uint8).ravel()\n",
    "    if mapped.size == 0:\n",
    "        return float('nan')\n",
    "    hist = np.bincount(mapped, minlength=256).astype(np.float64)\n",
    "    probs = hist / (hist.sum() + 1e-12)\n",
    "    probs = probs[probs > 0]\n",
    "    entropy_bits = -np.sum(probs * np.log2(probs))  # bits per symbol (channel)\n",
    "    # bits per pixel = entropy_bits * channels (3)\n",
    "    bpp = float(entropy_bits * 3.0)\n",
    "    return bpp\n",
    "\n",
    "def compute_lpips(a, b, lpips_model=None):\n",
    "    if not has_lpips or lpips_model is None: return float('nan')\n",
    "    with torch.no_grad(): return float(lpips_model(a, b).mean().item())\n",
    "\n",
    "# -----------------------------\n",
    "# Model definitions (same)\n",
    "# -----------------------------\n",
    "class CSPBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        split_point = max(in_channels // 2, 1)\n",
    "        self.split_point = split_point\n",
    "        self.part1 = nn.Sequential(\n",
    "            nn.Conv2d(split_point, split_point, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(split_point),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(split_point, split_point, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(split_point),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.Conv2d(split_point + (in_channels - split_point), out_channels, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        sp = self.split_point\n",
    "        x1, x2 = x[:, :sp], x[:, sp:]\n",
    "        y1 = self.part1(x1)\n",
    "        return self.transition(torch.cat((y1, x2), dim=1))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.csp1 = CSPBlock(64, 128)\n",
    "        self.down1 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.csp2 = CSPBlock(128, 128)\n",
    "        self.csp3 = CSPBlock(128, 64)\n",
    "        self.refine = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.final = nn.Sequential(nn.Conv2d(64, 3, 1), nn.Tanh())\n",
    "    def forward(self, cover, secret):\n",
    "        x = torch.cat((cover, secret), dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.csp1(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.csp2(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        x = self.csp3(x)\n",
    "        x = self.refine(x)\n",
    "        return self.final(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((4,4)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 4 * 4, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.main(x)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.conv(x)\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, base=64):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_channels, base)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = ConvBlock(base, base*2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = ConvBlock(base*2, base*4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = ConvBlock(base*4, base*8)\n",
    "        self.up1 = nn.ConvTranspose2d(base*8, base*4, 2, 2)\n",
    "        self.dec1 = ConvBlock(base*8, base*4)\n",
    "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, 2)\n",
    "        self.dec2 = ConvBlock(base*4, base*2)\n",
    "        self.up3 = nn.ConvTranspose2d(base*2, base, 2, 2)\n",
    "        self.dec3 = ConvBlock(base*2, base)\n",
    "        self.final_conv = nn.Conv2d(base, 3, 1)\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        d1 = self.up1(b)\n",
    "        if d1.size(2)!=e3.size(2): e3 = F.interpolate(e3,size=d1.shape[2:])\n",
    "        d1 = self.dec1(torch.cat([d1,e3],dim=1))\n",
    "        d2 = self.up2(d1)\n",
    "        if d2.size(2)!=e2.size(2): e2 = F.interpolate(e2,size=d2.shape[2:])\n",
    "        d2 = self.dec2(torch.cat([d2,e2],dim=1))\n",
    "        d3 = self.up3(d2)\n",
    "        if d3.size(2)!=e1.size(2): e1 = F.interpolate(e1,size=d3.shape[2:])\n",
    "        d3 = self.dec3(torch.cat([d3,e1],dim=1))\n",
    "        return torch.tanh(self.final_conv(d3))\n",
    "\n",
    "class VGGPerceptual(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features.to(device).eval()\n",
    "        for p in vgg.parameters(): p.requires_grad = False\n",
    "        self.vgg = vgg; self.layers = [4,9,16,23]\n",
    "    def forward(self, x):\n",
    "        feats=[]\n",
    "        for i,l in enumerate(self.vgg):\n",
    "            x=l(x)\n",
    "            if i in self.layers: feats.append(x)\n",
    "        return feats\n",
    "\n",
    "# -----------------------------\n",
    "# Initialize & train loop\n",
    "# -----------------------------\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "Dec = UNetDecoder(in_channels=3, base=64).to(device)\n",
    "VGG = VGGPerceptual(device)\n",
    "\n",
    "print(\"Models initialized\")\n",
    "\n",
    "# Data split & loaders\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_ds, val_ds = random_split(dataset, [len(dataset)-val_size, val_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "opt_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "opt_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "opt_Dec = optim.Adam(Dec.parameters(), lr=lr, betas=(0.5,0.999))\n",
    "\n",
    "sched_G = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_G, 'max', factor=0.5, patience=4)\n",
    "sched_Dec = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_Dec, 'max', factor=0.5, patience=4)\n",
    "\n",
    "mse_loss = nn.MSELoss()       # for LSGAN\n",
    "l1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "scaler_G = GradScaler()\n",
    "scaler_D = GradScaler()\n",
    "scaler_Dec = GradScaler()\n",
    "\n",
    "# LPIPS model init (if available)\n",
    "lpips_model = None\n",
    "if has_lpips:\n",
    "    try:\n",
    "        lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
    "    except Exception:\n",
    "        lpips_model = None\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop (with new eval metrics)\n",
    "# -----------------------------\n",
    "best_val_psnr = -1.0\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f\"runs_steg_{timestamp}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Logging containers\n",
    "train_D_losses, train_G_losses, train_Dec_losses = [], [], []\n",
    "val_psnr_hist, val_ssim_hist = [], []\n",
    "per_epoch_metrics = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, epochs+1):\n",
    "    G.train(); D.train(); Dec.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\")\n",
    "    iter_idx = 0\n",
    "    for cover, _ in pbar:\n",
    "        cover = cover.to(device)\n",
    "        secret = torch.flip(cover, dims=[-1]).to(device)\n",
    "\n",
    "        bs = cover.size(0)\n",
    "        real_label = torch.full((bs,1), 0.9, device=device)\n",
    "        fake_label = torch.zeros((bs,1), device=device)\n",
    "\n",
    "        # ---- Train D ----\n",
    "        opt_D.zero_grad()\n",
    "        with autocast():\n",
    "            with torch.no_grad():\n",
    "                gen_out = G(cover, secret)\n",
    "                stego_fake = torch.clamp(cover + 0.1 * gen_out, -1, 1)\n",
    "            pred_real = D(cover)\n",
    "            pred_fake = D(stego_fake)\n",
    "            D_loss = 0.5 * (mse_loss(pred_real, real_label) + mse_loss(pred_fake, fake_label))\n",
    "        scaler_D.scale(D_loss).backward(); scaler_D.step(opt_D); scaler_D.update()\n",
    "\n",
    "        # ---- Train G ----\n",
    "        opt_G.zero_grad()\n",
    "        for p in Dec.parameters(): p.requires_grad = False\n",
    "        with autocast():\n",
    "            gen_out = G(cover, secret)\n",
    "            stego = torch.clamp(cover + 0.1 * gen_out, -1, 1)\n",
    "            pred = D(stego)\n",
    "            adv_loss = mse_loss(pred, real_label)\n",
    "            ssim_loss = 1 - ssim(stego, cover, data_range=2.0, size_average=True)\n",
    "            recovered = Dec(stego)\n",
    "            rec_loss = l1(recovered, secret)\n",
    "            v_stego = VGG(tensor_to_vgg_input(stego))\n",
    "            v_cover = VGG(tensor_to_vgg_input(cover))\n",
    "            perc1 = sum(mse(a,b) for a,b in zip(v_stego, v_cover))\n",
    "            v_rec = VGG(tensor_to_vgg_input(recovered))\n",
    "            v_secret = VGG(tensor_to_vgg_input(secret))\n",
    "            perc2 = sum(mse(a,b) for a,b in zip(v_rec, v_secret))\n",
    "            perc_loss = (perc1 + perc2)\n",
    "            G_loss = 0.6 * adv_loss + lambda_ssim * ssim_loss + lambda_rec * rec_loss + lambda_perc * perc_loss\n",
    "        scaler_G.scale(G_loss).backward(); scaler_G.step(opt_G); scaler_G.update()\n",
    "        for p in Dec.parameters(): p.requires_grad = True\n",
    "\n",
    "        # ---- Train Decoder ----\n",
    "        opt_Dec.zero_grad()\n",
    "        with autocast():\n",
    "            rec_pred = Dec(stego.detach())\n",
    "            Dec_loss = l1(rec_pred, secret) + 0.1 * sum(mse(a,b) for a,b in zip(VGG(tensor_to_vgg_input(rec_pred)), VGG(tensor_to_vgg_input(secret))))\n",
    "        scaler_Dec.scale(Dec_loss).backward(); scaler_Dec.step(opt_Dec); scaler_Dec.update()\n",
    "\n",
    "        pbar.set_postfix({\"D_loss\": f\"{D_loss.item():.4f}\", \"G_loss\": f\"{G_loss.item():.4f}\", \"Dec_loss\": f\"{Dec_loss.item():.4f}\"})\n",
    "\n",
    "        train_D_losses.append(D_loss.item())\n",
    "        train_G_losses.append(G_loss.item())\n",
    "        train_Dec_losses.append(Dec_loss.item())\n",
    "\n",
    "        iter_idx += 1\n",
    "\n",
    "    # ---- Validation ----\n",
    "    G.eval(); Dec.eval()\n",
    "    val_psnrs = []\n",
    "    val_ssims = []\n",
    "    val_nrpcs = []\n",
    "    val_useis = []\n",
    "    val_lpips = []\n",
    "    val_recovery_accs = []\n",
    "    val_bpps = []\n",
    "    with torch.no_grad():\n",
    "        for j, (vcov, _) in enumerate(val_loader):\n",
    "            if j >= 50: break\n",
    "            vcov = vcov.to(device)\n",
    "            vsecret = torch.flip(vcov, dims=[-1]).to(device)\n",
    "            gen_out = G(vcov, vsecret)\n",
    "            vstego = torch.clamp(vcov + 0.1 * gen_out, -1, 1)\n",
    "            vrecovered = Dec(vstego)\n",
    "\n",
    "            # PSNR / SSIM / NRPC / USEI\n",
    "            val_psnrs.append(psnr_t(vrecovered, vsecret, 2.0))\n",
    "            try:\n",
    "                val_ssims.append(ssim(vrecovered, vsecret, data_range=2.0, size_average=True).item())\n",
    "            except Exception:\n",
    "                # fallback to skimage SSIM per image\n",
    "                a = ((vrecovered+1)/2).cpu().numpy()\n",
    "                b = ((vsecret+1)/2).cpu().numpy()\n",
    "                try:\n",
    "                    ssum = np.mean([ssim_sk(a[i].transpose(1,2,0), b[i].transpose(1,2,0), multichannel=True) for i in range(a.shape[0])])\n",
    "                    val_ssims.append(ssum)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            val_nrpcs.append(compute_nrpc(vcov, vstego))\n",
    "            val_useis.append(compute_usei_uqi(vrecovered, vsecret))\n",
    "\n",
    "            # LPIPS (optional)\n",
    "            if has_lpips and lpips_model is not None:\n",
    "                try:\n",
    "                    val_lpips.append(compute_lpips(vstego, vcov, lpips_model))\n",
    "                except Exception:\n",
    "                    val_lpips.append(float('nan'))\n",
    "\n",
    "            # Recovery accuracy (bitstream)\n",
    "            try:\n",
    "                acc = batch_bitstream_accuracy(vsecret, vrecovered)\n",
    "                val_recovery_accs.append(acc)\n",
    "            except Exception:\n",
    "                val_recovery_accs.append(float('nan'))\n",
    "\n",
    "            # Residual bpp estimate\n",
    "            try:\n",
    "                bpp = residual_bpp_estimate(vcov, vstego)\n",
    "                val_bpps.append(bpp)\n",
    "            except Exception:\n",
    "                val_bpps.append(float('nan'))\n",
    "\n",
    "    avg_val_psnr = float(np.nanmean(val_psnrs)) if len(val_psnrs)>0 else 0.0\n",
    "    avg_val_ssim = float(np.nanmean(val_ssims)) if len(val_ssims)>0 else 0.0\n",
    "    avg_val_nrpc = float(np.nanmean(val_nrpcs)) if len(val_nrpcs)>0 else float('nan')\n",
    "    avg_val_usei = float(np.nanmean(val_useis)) if len(val_useis)>0 else float('nan')\n",
    "    avg_val_lpips = float(np.nanmean(val_lpips)) if len(val_lpips)>0 else float('nan')\n",
    "    avg_val_recovery_acc = float(np.nanmean(val_recovery_accs)) if len(val_recovery_accs)>0 else float('nan')\n",
    "    avg_val_bpp = float(np.nanmean(val_bpps)) if len(val_bpps)>0 else float('nan')\n",
    "\n",
    "    print(f\"Epoch {epoch}: Avg Val PSNR = {avg_val_psnr:.3f} dB | SSIM = {avg_val_ssim:.4f} | NRPC = {avg_val_nrpc:.4f} | USEI(UQI) = {avg_val_usei:.4f} | LPIPS = {avg_val_lpips:.4f} | RecAcc = {avg_val_recovery_acc:.4f} | bpp = {avg_val_bpp:.4f}\")\n",
    "\n",
    "    val_psnr_hist.append(avg_val_psnr)\n",
    "    val_ssim_hist.append(avg_val_ssim)\n",
    "\n",
    "    per_epoch_metrics.append({\n",
    "        'epoch': epoch,\n",
    "        'psnr': avg_val_psnr,\n",
    "        'ssim': avg_val_ssim,\n",
    "        'nrpc': avg_val_nrpc,\n",
    "        'usei': avg_val_usei,\n",
    "        'lpips': avg_val_lpips,\n",
    "        'recovery_acc': avg_val_recovery_acc,\n",
    "        'bpp': avg_val_bpp\n",
    "    })\n",
    "\n",
    "    sched_G.step(avg_val_psnr)\n",
    "    sched_Dec.step(avg_val_psnr)\n",
    "\n",
    "    # save best\n",
    "    if avg_val_psnr > best_val_psnr:\n",
    "        best_val_psnr = avg_val_psnr\n",
    "        torch.save(G.state_dict(), os.path.join(log_dir, \"G_best.pth\"))\n",
    "        torch.save(Dec.state_dict(), os.path.join(log_dir, \"Dec_best.pth\"))\n",
    "        torch.save(D.state_dict(), os.path.join(log_dir, \"D_best.pth\"))\n",
    "        print(f\"Saved best models (PSNR {best_val_psnr:.2f} dB)\")\n",
    "\n",
    "    # periodic checkpoint\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save({\n",
    "            \"G\": G.state_dict(),\n",
    "            \"Dec\": Dec.state_dict(),\n",
    "            \"D\": D.state_dict(),\n",
    "            \"opt_G\": opt_G.state_dict(),\n",
    "            \"opt_Dec\": opt_Dec.state_dict(),\n",
    "            \"opt_D\": opt_D.state_dict(),\n",
    "            \"epoch\": epoch\n",
    "        }, os.path.join(log_dir, f\"checkpoint_epoch_{epoch}.pth\"))\n",
    "\n",
    "print(\"Training finished. Best PSNR:\", best_val_psnr)\n",
    "\n",
    "# -----------------------------\n",
    "# Final Inference / Visualization\n",
    "# -----------------------------\n",
    "G.load_state_dict(torch.load(os.path.join(log_dir,\"G_best.pth\"), map_location=device))\n",
    "Dec.load_state_dict(torch.load(os.path.join(log_dir,\"Dec_best.pth\"), map_location=device))\n",
    "G.eval(); Dec.eval()\n",
    "\n",
    "sample, _ = next(iter(val_loader))\n",
    "cover_samp = sample[:8].to(device)\n",
    "secret_samp = torch.flip(cover_samp, dims=[-1]).to(device)\n",
    "with torch.no_grad():\n",
    "    gen_out = G(cover_samp, secret_samp)\n",
    "    stego_samp = torch.clamp(cover_samp + 0.1 * gen_out, -1, 1)\n",
    "    recovered_samp = Dec(stego_samp)\n",
    "\n",
    "# Save sample grid\n",
    "try:\n",
    "    grid = make_grid(torch.cat([cover_samp, secret_samp, stego_samp, recovered_samp], dim=0), nrow=8)\n",
    "    save_path = os.path.join(log_dir, \"stegano_results_best.png\")\n",
    "    save_image(((grid+1)/2).clamp(0,1), save_path)\n",
    "    print(\"Saved visualization to\", save_path)\n",
    "except Exception as e:\n",
    "    print(\"Failed to save sample grid:\", e)\n",
    "\n",
    "# per-epoch metrics CSV\n",
    "metrics_df = pd.DataFrame(per_epoch_metrics)\n",
    "metrics_df.to_csv(os.path.join(log_dir, 'per_epoch_metrics.csv'), index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting: one graph per metric (saved individually)\n",
    "# -----------------------------\n",
    "# Helper for plotting\n",
    "def save_metric_plot(x, y, title, ylabel, save_path):\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(x, y, marker='o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "epochs_arr = metrics_df['epoch'].tolist()\n",
    "\n",
    "# PSNR\n",
    "save_metric_plot(epochs_arr, metrics_df['psnr'].tolist(), 'Validation PSNR across epochs', 'PSNR (dB)', os.path.join(log_dir, 'val_psnr.png'))\n",
    "\n",
    "# SSIM\n",
    "save_metric_plot(epochs_arr, metrics_df['ssim'].tolist(), 'Validation SSIM across epochs', 'SSIM', os.path.join(log_dir, 'val_ssim.png'))\n",
    "\n",
    "# NRPC\n",
    "save_metric_plot(epochs_arr, metrics_df['nrpc'].tolist(), 'Validation NRPC across epochs', 'NRPC', os.path.join(log_dir, 'val_nrpc.png'))\n",
    "\n",
    "# USEI / UQI\n",
    "save_metric_plot(epochs_arr, metrics_df['usei'].tolist(), 'Validation USEI (UQI) across epochs', 'USEI (UQI)', os.path.join(log_dir, 'val_usei.png'))\n",
    "\n",
    "# LPIPS\n",
    "save_metric_plot(epochs_arr, metrics_df['lpips'].tolist(), 'Validation LPIPS across epochs', 'LPIPS', os.path.join(log_dir, 'val_lpips.png'))\n",
    "\n",
    "# Recovery accuracy (bitstream)\n",
    "save_metric_plot(epochs_arr, metrics_df['recovery_acc'].tolist(), 'Recovery Bitstream Accuracy across epochs', 'Accuracy (fraction)', os.path.join(log_dir, 'val_recovery_acc.png'))\n",
    "\n",
    "# Residual capacity (bpp)\n",
    "save_metric_plot(epochs_arr, metrics_df['bpp'].tolist(), 'Estimated Residual Capacity (bpp) across epochs', 'bits per pixel (bpp)', os.path.join(log_dir, 'val_bpp.png'))\n",
    "\n",
    "# Combined training losses plot (per iteration)\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot(train_G_losses, label='Generator Loss')\n",
    "plt.plot(train_D_losses, label='Discriminator Loss')\n",
    "plt.plot(train_Dec_losses, label='Decoder Loss')\n",
    "plt.title('Training Losses (per iteration)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(log_dir, 'training_losses_per_iter.png'))\n",
    "plt.close()\n",
    "\n",
    "# Histogram of residuals (sample)\n",
    "try:\n",
    "    resid = ((stego_samp - cover_samp).detach().cpu().numpy()).flatten()\n",
    "    plt.hist(resid, bins=100)\n",
    "    plt.title('Histogram of Residuals (stego - cover) [sample]')\n",
    "    plt.savefig(os.path.join(log_dir, 'residual_hist.png'))\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print('Failed residual histogram:', e)\n",
    "\n",
    "print('All plots, CSVs and sample images saved to', log_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
